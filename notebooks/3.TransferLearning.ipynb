{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMD_qlIwYEyu"
   },
   "source": [
    "# AIM\n",
    "In this notebook we train top layers of Deep CNNs (transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root=PosixPath('/home/gnacikm/Documents/GitHub/Melanoma')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "#Set root to be the main project folder\n",
    "root = Path.cwd().parent\n",
    "print(f\"{root=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path=PosixPath('/home/gnacikm/Documents/GitHub/Melanoma/data')\n",
      "sav_models =PosixPath('/home/gnacikm/Documents/GitHub/Melanoma/saved_models')\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(root/'data')\n",
    "print(f\"{data_path=}\")\n",
    "sav_models = Path(root/'saved_models')\n",
    "print(f\"{sav_models =}\")\n",
    "\n",
    "#Add location of py files to path so we can import\n",
    "sys.path.insert(0,str(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES / PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 09:50:25.705528: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.deepnet import DeepNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Methods from Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import ImageGenerator, FlowFromDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if GPU has been detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU /device:GPU:0 found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 08:49:47.706900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-06 08:49:47.710769: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-06 08:49:47.766718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:47.767032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 980 computeCapability: 5.2\n",
      "coreClock: 1.329GHz coreCount: 16 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 208.91GiB/s\n",
      "2021-08-06 08:49:47.767048: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-06 08:49:47.769368: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-06 08:49:47.769484: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-06 08:49:47.770517: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-06 08:49:47.770763: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-06 08:49:47.772953: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-06 08:49:47.773461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-06 08:49:47.773572: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-06 08:49:47.773649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:47.774232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:47.774600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-06 08:49:47.774627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-06 08:49:48.247916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-06 08:49:48.247938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-06 08:49:48.247944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-06 08:49:48.248072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:48.248334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:48.248563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:48.248772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 2605 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980, pci bus id: 0000:02:00.0, compute capability: 5.2)\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '':\n",
    "    raise SystemError(\"GPU not found\")\n",
    "else:\n",
    "    print(f\"GPU {device_name} found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_with_zip = data_path\n",
    "dir_with_data = f\"{dir_with_zip}/DermMel\" \n",
    "path_train = f\"{dir_with_data}/train_sep/\"\n",
    "path_val = f\"{dir_with_data}/valid/\"\n",
    "path_test = f\"{dir_with_data}/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ImageDataGenerator\n",
    "See https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qSM4Is7N3JXd"
   },
   "outputs": [],
   "source": [
    "data_train = ImageGenerator()\n",
    "data_val = ImageGenerator()\n",
    "data_test = ImageGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10683 images belonging to 2 classes.\n",
      "Found 3562 images belonging to 2 classes.\n",
      "Found 3561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = FlowFromDir(\n",
    "    data_train,\n",
    "    path_train,\n",
    "    target_size=(160, 160),\n",
    "    shuffle=True)\n",
    "val_generator = FlowFromDir(\n",
    "    data_val,\n",
    "    path_val,\n",
    "    target_size=(160, 160),\n",
    "    shuffle=True)\n",
    "test_generator = FlowFromDir(\n",
    "    data_test,\n",
    "    path_test,\n",
    "    target_size=(160, 160),\n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = train_generator[0][0].shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = train_generator[0][1][0].shape[0]\n",
    "num_of_classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2 - Initiating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 08:49:56.618993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.619358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 980 computeCapability: 5.2\n",
      "coreClock: 1.329GHz coreCount: 16 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 208.91GiB/s\n",
      "2021-08-06 08:49:56.619449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.619806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.620090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-06 08:49:56.620407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.620691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 980 computeCapability: 5.2\n",
      "coreClock: 1.329GHz coreCount: 16 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 208.91GiB/s\n",
      "2021-08-06 08:49:56.620750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.621065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.621340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-08-06 08:49:56.621369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-06 08:49:56.621377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-08-06 08:49:56.621384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-08-06 08:49:56.621470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.621826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-06 08:49:56.622089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2605 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980, pci bus id: 0000:02:00.0, compute capability: 5.2)\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                                    include_top=False,\n",
    "                                                    weights='imagenet',\n",
    "                                                    pooling=None, \n",
    "                                                    classifier_activation=\"softmax\"\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobModel = DeepNet(mobilenetv2_model, num_of_classes)\n",
    "MobModel.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    sav_models/\"weights/mobnet.h5\", \n",
    "    monitor = \"val_accuracy\", \n",
    "    verbose = 2, \n",
    "    save_weights_only=True,\n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 14:37:34.430798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-05 14:37:34.877954: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2021-08-05 14:37:35.211361: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 14:37:35.211386: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-08-05 14:37:35.211785: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 14:37:35.211862: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-08-05 14:37:35.239227: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-05 14:37:35.689265: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-05 14:37:35.853068: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-05 14:37:35.853601: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3399905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 14:37:40.306741: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 376.59MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.316962: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 489.09MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.342671: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 827.17MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.383598: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 962.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.522743: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 923.81MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.532495: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.593241: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 692.95MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.606107: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 737.17MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.624090: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 359.36MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 14:37:40.629918: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 489.09MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 162s 944ms/step - loss: 0.3092 - accuracy: 0.8739 - val_loss: 0.6272 - val_accuracy: 0.5361\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53608, saving model to weights/mobnet.h5\n",
      "Epoch 2/15\n",
      "166/166 [==============================] - 149s 896ms/step - loss: 0.2080 - accuracy: 0.9201 - val_loss: 0.1877 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.53608 to 0.92699, saving model to weights/mobnet.h5\n",
      "Epoch 3/15\n",
      "166/166 [==============================] - 146s 874ms/step - loss: 0.1791 - accuracy: 0.9293 - val_loss: 0.1599 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.92699 to 0.93977, saving model to weights/mobnet.h5\n",
      "Epoch 4/15\n",
      "166/166 [==============================] - 181s 1s/step - loss: 0.1636 - accuracy: 0.9376 - val_loss: 0.1392 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.93977 to 0.94261, saving model to weights/mobnet.h5\n",
      "Epoch 5/15\n",
      "166/166 [==============================] - 125s 751ms/step - loss: 0.1968 - accuracy: 0.9286 - val_loss: 0.1475 - val_accuracy: 0.9418\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.94261\n",
      "Epoch 6/15\n",
      "166/166 [==============================] - 125s 752ms/step - loss: 0.1633 - accuracy: 0.9387 - val_loss: 0.1867 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.94261\n",
      "Epoch 7/15\n",
      "166/166 [==============================] - 129s 777ms/step - loss: 0.1655 - accuracy: 0.9370 - val_loss: 0.1362 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.94261 to 0.94432, saving model to weights/mobnet.h5\n",
      "Epoch 8/15\n",
      "166/166 [==============================] - 124s 745ms/step - loss: 0.1421 - accuracy: 0.9417 - val_loss: 0.1342 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.94432 to 0.94517, saving model to weights/mobnet.h5\n",
      "Epoch 9/15\n",
      "166/166 [==============================] - 125s 749ms/step - loss: 0.1361 - accuracy: 0.9486 - val_loss: 0.1315 - val_accuracy: 0.9469\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.94517 to 0.94687, saving model to weights/mobnet.h5\n",
      "Epoch 10/15\n",
      "166/166 [==============================] - 116s 700ms/step - loss: 0.1537 - accuracy: 0.9378 - val_loss: 0.1650 - val_accuracy: 0.9366\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.94687\n",
      "Epoch 11/15\n",
      "166/166 [==============================] - 116s 700ms/step - loss: 0.1245 - accuracy: 0.9527 - val_loss: 0.1493 - val_accuracy: 0.9418\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.94687\n",
      "Epoch 12/15\n",
      "166/166 [==============================] - 116s 697ms/step - loss: 0.1256 - accuracy: 0.9515 - val_loss: 0.1454 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.94687\n",
      "Epoch 13/15\n",
      "166/166 [==============================] - 135s 811ms/step - loss: 0.1113 - accuracy: 0.9565 - val_loss: 0.1249 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.94687 to 0.95142, saving model to weights/mobnet.h5\n",
      "Epoch 14/15\n",
      "166/166 [==============================] - 132s 795ms/step - loss: 0.1104 - accuracy: 0.9541 - val_loss: 0.1419 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.95142\n",
      "Epoch 15/15\n",
      "166/166 [==============================] - 140s 840ms/step - loss: 0.1003 - accuracy: 0.9624 - val_loss: 0.1581 - val_accuracy: 0.9378\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.95142\n"
     ]
    }
   ],
   "source": [
    "history_mob = MobModel.fit(train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               153720    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 170       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0 (unused)\n",
      "=================================================================\n",
      "Total params: 2,422,038\n",
      "Trainable params: 2,387,926\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "Model: \"deep_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               153720    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 170       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0 (unused)\n",
      "=================================================================\n",
      "Total params: 2,422,038\n",
      "Trainable params: 2,387,926\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MobModel.call(inputs)\n",
    "MobModel.built = True \n",
    "MobModel.load_weights(sav_models/\"weights/mobnet.h5\")\n",
    "MobModel.summary()\n",
    "MobModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 08:50:12.322697: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-06 08:50:12.342598: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3399905000 Hz\n",
      "2021-08-06 08:50:13.299782: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-06 08:50:13.613235: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2021-08-06 08:50:13.856646: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-06 08:50:13.856671: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-08-06 08:50:13.857250: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-06 08:50:13.857312: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-08-06 08:50:13.863700: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-06 08:50:14.050183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3561/3561 [==============================] - 37s 10ms/step - loss: 0.1342 - accuracy: 0.9461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13421431183815002, 0.9460825324058533]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "MobModel.evaluate(test_generator, steps=test_generator.n//test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 - Initiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    "    pooling=None, \n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vgg19Model = DeepNet(vgg19_model, num_of_classes)\n",
    "Vgg19Model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    sav_models/\"weights/vgg19.h5\", \n",
    "    monitor = \"val_accuracy\", \n",
    "    verbose = 2, \n",
    "    save_weights_only=True,\n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 15:26:16.120282: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-05 15:26:16.446528: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2021-08-05 15:26:16.713274: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 15:26:16.713310: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-08-05 15:26:16.713774: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 15:26:16.713896: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-08-05 15:26:16.731858: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:16.772099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-05 15:26:16.983937: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-05 15:26:17.129998: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.53GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:17.180688: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.77GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:17.301236: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:17.434401: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.77GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:17.434465: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:17.803931: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:18.369395: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.42GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:18.719826: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-05 15:26:18.720215: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3399905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 15:26:20.325484: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:20.491138: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.53GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 15:26:22.869758: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 269s 2s/step - loss: 0.4903 - accuracy: 0.7667 - val_loss: 0.4361 - val_accuracy: 0.8097\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80966, saving model to weights/vgg19.h5\n",
      "Epoch 2/15\n",
      "166/166 [==============================] - 223s 1s/step - loss: 0.3825 - accuracy: 0.8424 - val_loss: 0.3824 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.80966 to 0.82642, saving model to weights/vgg19.h5\n",
      "Epoch 3/15\n",
      "166/166 [==============================] - 213s 1s/step - loss: 0.3635 - accuracy: 0.8450 - val_loss: 0.4225 - val_accuracy: 0.8236\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.82642\n",
      "Epoch 4/15\n",
      "166/166 [==============================] - 210s 1s/step - loss: 0.3124 - accuracy: 0.8732 - val_loss: 0.2668 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.82642 to 0.88778, saving model to weights/vgg19.h5\n",
      "Epoch 5/15\n",
      "166/166 [==============================] - 208s 1s/step - loss: 0.2947 - accuracy: 0.8800 - val_loss: 0.2435 - val_accuracy: 0.9006\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.88778 to 0.90057, saving model to weights/vgg19.h5\n",
      "Epoch 6/15\n",
      "166/166 [==============================] - 200s 1s/step - loss: 0.2617 - accuracy: 0.8945 - val_loss: 0.3251 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.90057\n",
      "Epoch 7/15\n",
      "166/166 [==============================] - 194s 1s/step - loss: 0.2490 - accuracy: 0.9032 - val_loss: 0.2180 - val_accuracy: 0.9134\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.90057 to 0.91335, saving model to weights/vgg19.h5\n",
      "Epoch 8/15\n",
      "166/166 [==============================] - 196s 1s/step - loss: 0.2079 - accuracy: 0.9180 - val_loss: 0.1775 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91335 to 0.93182, saving model to weights/vgg19.h5\n",
      "Epoch 9/15\n",
      "166/166 [==============================] - 210s 1s/step - loss: 0.1739 - accuracy: 0.9307 - val_loss: 0.1559 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.93182 to 0.93523, saving model to weights/vgg19.h5\n",
      "Epoch 10/15\n",
      "166/166 [==============================] - 263s 2s/step - loss: 0.1605 - accuracy: 0.9342 - val_loss: 0.1602 - val_accuracy: 0.9403\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.93523 to 0.94034, saving model to weights/vgg19.h5\n",
      "Epoch 11/15\n",
      "166/166 [==============================] - 259s 2s/step - loss: 0.1414 - accuracy: 0.9438 - val_loss: 0.1556 - val_accuracy: 0.9435\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.94034 to 0.94347, saving model to weights/vgg19.h5\n",
      "Epoch 12/15\n",
      "166/166 [==============================] - 256s 2s/step - loss: 0.1458 - accuracy: 0.9406 - val_loss: 0.1429 - val_accuracy: 0.9435\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.94347\n",
      "Epoch 13/15\n",
      "166/166 [==============================] - 256s 2s/step - loss: 0.1293 - accuracy: 0.9462 - val_loss: 0.1548 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.94347 to 0.94886, saving model to weights/vgg19.h5\n",
      "Epoch 14/15\n",
      "166/166 [==============================] - 258s 2s/step - loss: 0.1314 - accuracy: 0.9473 - val_loss: 0.1300 - val_accuracy: 0.9477\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.94886\n",
      "Epoch 15/15\n",
      "166/166 [==============================] - 265s 2s/step - loss: 0.1160 - accuracy: 0.9521 - val_loss: 0.2465 - val_accuracy: 0.8932\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.94886\n"
     ]
    }
   ],
   "source": [
    "history_vgg = Vgg19Model.fit(train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_net_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 5, 5, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  61560     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  170       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 20,096,278\n",
      "Trainable params: 20,096,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Vgg19Model.call(inputs)\n",
    "Vgg19Model.built = True\n",
    "Vgg19Model.load_weights(sav_models/\"weights/vgg19.h5\")\n",
    "Vgg19Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3561/3561 [==============================] - 43s 12ms/step - loss: 0.1683 - accuracy: 0.9399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16827549040317535, 0.939904510974884]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "Vgg19Model.evaluate(test_generator, steps=test_generator.n//test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50V2 - Initiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False, \n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetModel = DeepNet(resnet_model, num_of_classes)\n",
    "ResNetModel.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    sav_models/\"weights/resnet.h5\", \n",
    "    monitor = \"val_accuracy\", \n",
    "    verbose = 2, \n",
    "    save_weights_only=True,\n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 18:21:35.891103: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-05 18:21:36.138894: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2021-08-05 18:21:36.359162: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 18:21:36.359201: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-08-05 18:21:36.359918: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 18:21:36.360105: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-08-05 18:21:36.376098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-05 18:21:36.544638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-05 18:21:36.731433: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-05 18:21:36.750564: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3399905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 18:21:40.161387: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:40.172937: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:40.289055: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:40.295478: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:40.355792: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:40.361713: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/667 [====>.........................] - ETA: 1:11 - loss: 0.5710 - accuracy: 0.7138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 18:21:56.900762: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:56.910151: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:56.922276: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-08-05 18:21:56.928689: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 116s 168ms/step - loss: 0.4297 - accuracy: 0.8065 - val_loss: 0.3858 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80828, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/resnet.h5\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.3275 - accuracy: 0.8645 - val_loss: 0.2966 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.80828 to 0.87218, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/resnet.h5\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.2944 - accuracy: 0.8784 - val_loss: 0.2277 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.87218 to 0.90597, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/resnet.h5\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 112s 167ms/step - loss: 0.2709 - accuracy: 0.8911 - val_loss: 0.2833 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.90597\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.2527 - accuracy: 0.8930 - val_loss: 0.2411 - val_accuracy: 0.9017\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.90597\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 110s 165ms/step - loss: 0.2279 - accuracy: 0.9050 - val_loss: 0.2283 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.90597 to 0.90625, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/resnet.h5\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.2109 - accuracy: 0.9167 - val_loss: 0.2395 - val_accuracy: 0.8916\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.90625\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.2058 - accuracy: 0.9153 - val_loss: 0.2442 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.90625\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 112s 168ms/step - loss: 0.1862 - accuracy: 0.9255 - val_loss: 0.2482 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.90625\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.1735 - accuracy: 0.9284 - val_loss: 0.2154 - val_accuracy: 0.8984\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.90625\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.1536 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.8992\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.90625\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 111s 166ms/step - loss: 0.1486 - accuracy: 0.9391 - val_loss: 0.1994 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.90625 to 0.91441, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/resnet.h5\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 114s 170ms/step - loss: 0.1309 - accuracy: 0.9482 - val_loss: 0.3063 - val_accuracy: 0.9017\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91441\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 115s 172ms/step - loss: 0.1239 - accuracy: 0.9513 - val_loss: 0.2318 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91441\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 114s 171ms/step - loss: 0.1240 - accuracy: 0.9541 - val_loss: 0.2832 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91441\n"
     ]
    }
   ],
   "source": [
    "history_res = ResNetModel.fit(train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_net_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  245880    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  170       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 23,821,014\n",
      "Trainable params: 23,775,574\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ResNetModel.call(inputs)\n",
    "ResNetModel.built = True \n",
    "ResNetModel.load_weights(sav_models/\"weights/resnet.h5\")\n",
    "ResNetModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3561/3561 [==============================] - 41s 12ms/step - loss: 0.2095 - accuracy: 0.9096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20945307612419128, 0.9095759391784668]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "ResNetModel.evaluate(test_generator, steps=test_generator.n//test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception - Initiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model = tf.keras.applications.xception.Xception(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=input_shape,\n",
    "    pooling=None, \n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "XcpModel = DeepNet(xception_model, num_of_classes)\n",
    "XcpModel.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    sav_models/\"weights/xception.h5\", \n",
    "    monitor = \"val_accuracy\", \n",
    "    verbose = 2, \n",
    "    save_weights_only=True,\n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "667/667 [==============================] - 189s 279ms/step - loss: 0.2950 - accuracy: 0.8817 - val_loss: 0.1576 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93806, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 2/15\n",
      "667/667 [==============================] - 182s 273ms/step - loss: 0.2821 - accuracy: 0.8928 - val_loss: 0.1629 - val_accuracy: 0.9372\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.93806\n",
      "Epoch 3/15\n",
      "667/667 [==============================] - 181s 271ms/step - loss: 0.1739 - accuracy: 0.9307 - val_loss: 0.1509 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.93806\n",
      "Epoch 4/15\n",
      "667/667 [==============================] - 186s 279ms/step - loss: 0.1655 - accuracy: 0.9352 - val_loss: 0.1537 - val_accuracy: 0.9395\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.93806 to 0.93947, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 5/15\n",
      "667/667 [==============================] - 193s 290ms/step - loss: 0.1571 - accuracy: 0.9391 - val_loss: 0.1508 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.93947 to 0.94200, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 6/15\n",
      "667/667 [==============================] - 199s 298ms/step - loss: 0.1585 - accuracy: 0.9364 - val_loss: 0.1727 - val_accuracy: 0.9383\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.94200\n",
      "Epoch 7/15\n",
      "667/667 [==============================] - 198s 296ms/step - loss: 0.1508 - accuracy: 0.9389 - val_loss: 0.1408 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.94200 to 0.94285, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 8/15\n",
      "667/667 [==============================] - 200s 300ms/step - loss: 0.1414 - accuracy: 0.9406 - val_loss: 0.1573 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.94285\n",
      "Epoch 9/15\n",
      "667/667 [==============================] - 199s 298ms/step - loss: 0.1268 - accuracy: 0.9475 - val_loss: 0.1420 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.94285 to 0.94651, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 10/15\n",
      "667/667 [==============================] - 197s 296ms/step - loss: 0.1231 - accuracy: 0.9490 - val_loss: 0.1280 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.94651\n",
      "Epoch 11/15\n",
      "667/667 [==============================] - 197s 295ms/step - loss: 0.1127 - accuracy: 0.9543 - val_loss: 0.1442 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.94651 to 0.94707, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 12/15\n",
      "667/667 [==============================] - 197s 295ms/step - loss: 0.0934 - accuracy: 0.9632 - val_loss: 0.1346 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.94707 to 0.95270, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 13/15\n",
      "667/667 [==============================] - 199s 298ms/step - loss: 0.0830 - accuracy: 0.9682 - val_loss: 0.1175 - val_accuracy: 0.9586\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.95270 to 0.95861, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/xception.h5\n",
      "Epoch 14/15\n",
      "667/667 [==============================] - 195s 292ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 0.1319 - val_accuracy: 0.9474\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.95861\n",
      "Epoch 15/15\n",
      "667/667 [==============================] - 193s 290ms/step - loss: 0.0597 - accuracy: 0.9787 - val_loss: 0.1465 - val_accuracy: 0.9569\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.95861\n"
     ]
    }
   ],
   "source": [
    "history_xcp = XcpModel.fit(train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_net_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  245880    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  170       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 21,117,694\n",
      "Trainable params: 21,063,166\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "XcpModel.call(inputs)\n",
    "XcpModel.built = True \n",
    "XcpModel.load_weights(sav_models/\"weights/xception.h5\")\n",
    "XcpModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3561/3561 [==============================] - 41s 11ms/step - loss: 0.1243 - accuracy: 0.9523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12426680326461792, 0.9522606134414673]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "XcpModel.evaluate(test_generator, steps=test_generator.n//test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter_Search_melanoma_best.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test_mel",
   "language": "python",
   "name": "test_mel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
