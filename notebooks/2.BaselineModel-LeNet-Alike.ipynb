{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMD_qlIwYEyu"
   },
   "source": [
    "# AIM\n",
    "In this notebook we train our baseline model which has a similar architecture of Le-Net5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root=PosixPath('/home/gnacikm/Documents/GitHub/Melanoma')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "#Set root to be the main project folder\n",
    "root = Path.cwd().parent\n",
    "print(f\"{root=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path=PosixPath('/home/gnacikm/Documents/GitHub/Melanoma/data')\n",
      "sav_models =PosixPath('/home/gnacikm/Documents/GitHub/Melanoma/saved_models')\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(root/'data')\n",
    "print(f\"{data_path=}\")\n",
    "sav_models = Path(root/'saved_models')\n",
    "print(f\"{sav_models =}\")\n",
    "\n",
    "#Add location of py files to path so we can import\n",
    "sys.path.insert(0,str(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES / PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lenet import LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Methods from Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import ImageGenerator, FlowFromDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if GPU has been detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU /device:GPU:0 found\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '':\n",
    "    raise SystemError(\"GPU not found\")\n",
    "else:\n",
    "    print(f\"GPU {device_name} found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_with_zip = data_path\n",
    "dir_with_data = f\"{dir_with_zip}/DermMel\" \n",
    "path_train = f\"{dir_with_data}/train_sep/\"\n",
    "path_val = f\"{dir_with_data}/valid/\"\n",
    "path_test = f\"{dir_with_data}/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ImageDataGenerator\n",
    "See https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qSM4Is7N3JXd"
   },
   "outputs": [],
   "source": [
    "data_train = ImageGenerator()\n",
    "data_val = ImageGenerator()\n",
    "data_test = ImageGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10683 images belonging to 2 classes.\n",
      "Found 3562 images belonging to 2 classes.\n",
      "Found 3561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = FlowFromDir(\n",
    "    data_train,\n",
    "    path_train,\n",
    "    shuffle=True)\n",
    "val_generator = FlowFromDir(\n",
    "    data_val,\n",
    "    path_val,\n",
    "    shuffle=True)\n",
    "test_generator = FlowFromDir(\n",
    "    data_test,\n",
    "    path_test,\n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = train_generator[0][0].shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = train_generator[0][1][0].shape[0]\n",
    "num_of_classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "inputs = tf.keras.Input(input_shape, name=\"img\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaselineModel = LeNet(num_of_classes)\n",
    "BaselineModel.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 08:44:01.390224: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-06 08:44:01.390277: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-06 08:44:01.398224: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-08-06 08:44:01.398579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2021-08-06 08:44:01.419041: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n",
      "2021-08-06 08:44:01.522180: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2021-08-06 08:44:01.522439: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard https://www.tensorflow.org/tensorboard/scalars_and_keras\n",
    "logdir = \"../logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    sav_models/\"weights/lenet.h5\", \n",
    "    monitor = \"val_accuracy\", \n",
    "    verbose = 2, \n",
    "    save_weights_only=True,\n",
    "    save_best_only = True,\n",
    "    mode = 'max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 17:38:10.295988: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-08-05 17:38:11.805549: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2021-08-05 17:38:13.601702: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 17:38:13.601790: W tensorflow/stream_executor/gpu/asm_compiler.cc:56] Couldn't invoke ptxas --version\n",
      "2021-08-05 17:38:13.603576: E tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-08-05 17:38:13.603845: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-08-05 17:38:13.658118: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-05 17:38:14.680099: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-05 17:38:14.826094: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-05 17:38:14.846543: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3399905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  3/667 [..............................] - ETA: 1:02 - loss: 0.7632 - accuracy: 0.4792 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 17:38:16.110211: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-05 17:38:16.110239: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-05 17:38:16.111064: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2021-08-05 17:38:16.129030: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-08-05 17:38:16.132419: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-08-05 17:38:16.134679: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-08-05 17:38:16.143181: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16\n",
      "2021-08-05 17:38:16.143657: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.trace.json.gz\n",
      "2021-08-05 17:38:16.166775: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16\n",
      "2021-08-05 17:38:16.168195: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.memory_profile.json.gz\n",
      "2021-08-05 17:38:16.168418: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16Dumped tool data for xplane.pb to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ../logs/scalars/20210805-173805/train/plugins/profile/2021_08_05_17_38_16/gnacikm-System-Product-Name.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/667 [==============================] - 126s 187ms/step - loss: 0.6106 - accuracy: 0.6404 - val_loss: 0.5687 - val_accuracy: 0.6681\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66807, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 2/20\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.5507 - accuracy: 0.6896 - val_loss: 0.5072 - val_accuracy: 0.6858\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66807 to 0.68581, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 3/20\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.5140 - accuracy: 0.7295 - val_loss: 0.4914 - val_accuracy: 0.7801\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.68581 to 0.78012, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 4/20\n",
      "667/667 [==============================] - 105s 157ms/step - loss: 0.4722 - accuracy: 0.7727 - val_loss: 0.4336 - val_accuracy: 0.8252\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78012 to 0.82517, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 5/20\n",
      "667/667 [==============================] - 102s 153ms/step - loss: 0.4302 - accuracy: 0.8013 - val_loss: 0.4094 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.82517\n",
      "Epoch 6/20\n",
      "667/667 [==============================] - 101s 151ms/step - loss: 0.4143 - accuracy: 0.8193 - val_loss: 0.4152 - val_accuracy: 0.8139\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.82517\n",
      "Epoch 7/20\n",
      "667/667 [==============================] - 101s 151ms/step - loss: 0.3800 - accuracy: 0.8302 - val_loss: 0.3402 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.82517 to 0.85529, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 8/20\n",
      "667/667 [==============================] - 103s 155ms/step - loss: 0.3645 - accuracy: 0.8411 - val_loss: 0.3656 - val_accuracy: 0.8302\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.85529\n",
      "Epoch 9/20\n",
      "667/667 [==============================] - 108s 162ms/step - loss: 0.3458 - accuracy: 0.8517 - val_loss: 0.3440 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.85529\n",
      "Epoch 10/20\n",
      "667/667 [==============================] - 103s 155ms/step - loss: 0.3365 - accuracy: 0.8562 - val_loss: 0.3179 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.85529 to 0.86571, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 11/20\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.3238 - accuracy: 0.8604 - val_loss: 0.3735 - val_accuracy: 0.8302\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.86571\n",
      "Epoch 12/20\n",
      "667/667 [==============================] - 102s 153ms/step - loss: 0.3090 - accuracy: 0.8677 - val_loss: 0.2938 - val_accuracy: 0.8789\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.86571 to 0.87894, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 13/20\n",
      "667/667 [==============================] - 102s 153ms/step - loss: 0.2993 - accuracy: 0.8718 - val_loss: 0.3019 - val_accuracy: 0.8744\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.87894\n",
      "Epoch 14/20\n",
      "667/667 [==============================] - 99s 149ms/step - loss: 0.2883 - accuracy: 0.8782 - val_loss: 0.3754 - val_accuracy: 0.8353\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.87894\n",
      "Epoch 15/20\n",
      "667/667 [==============================] - 100s 149ms/step - loss: 0.2868 - accuracy: 0.8764 - val_loss: 0.2948 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.87894\n",
      "Epoch 16/20\n",
      "667/667 [==============================] - 100s 150ms/step - loss: 0.2705 - accuracy: 0.8878 - val_loss: 0.2640 - val_accuracy: 0.8939\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.87894 to 0.89386, saving model to /home/gnacikm/Documents/GitHub/Melanoma/saved_models/weights/lenet.h5\n",
      "Epoch 17/20\n",
      "667/667 [==============================] - 101s 151ms/step - loss: 0.2729 - accuracy: 0.8869 - val_loss: 0.2793 - val_accuracy: 0.8840\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89386\n",
      "Epoch 18/20\n",
      "667/667 [==============================] - 106s 158ms/step - loss: 0.2572 - accuracy: 0.8943 - val_loss: 0.2879 - val_accuracy: 0.8815\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89386\n",
      "Epoch 19/20\n",
      "667/667 [==============================] - 104s 156ms/step - loss: 0.2478 - accuracy: 0.8965 - val_loss: 0.3040 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89386\n",
      "Epoch 20/20\n",
      "667/667 [==============================] - 102s 154ms/step - loss: 0.2444 - accuracy: 0.8987 - val_loss: 0.2924 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.89386\n"
     ]
    }
   ],
   "source": [
    "history = BaselineModel.fit(train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=val_generator.n//val_generator.batch_size,\n",
    "                    callbacks=[tensorboard_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"le_net_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 158, 158, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 77, 77, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 92416)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               11090040  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 170       \n",
      "=================================================================\n",
      "Total params: 11,119,766\n",
      "Trainable params: 11,119,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 08:46:23.342325: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 44359680 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "BaselineModel.call(inputs)\n",
    "BaselineModel.built = True \n",
    "BaselineModel.load_weights(sav_models/\"weights/lenet.h5\")\n",
    "BaselineModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-54f8102fe90a8944\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-54f8102fe90a8944\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/subprocess.py:946: ResourceWarning: subprocess 56020 is still running\n",
      "  _warn(\"subprocess %s is still running\" % self.pid,\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../logs/scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3561/3561 [==============================] - 30s 8ms/step - loss: 0.2679 - accuracy: 0.8863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26792553067207336, 0.886267900466919]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "BaselineModel.evaluate(test_generator, steps=test_generator.n//test_generator.batch_size )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter_Search_melanoma_best.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test_mel",
   "language": "python",
   "name": "test_mel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
